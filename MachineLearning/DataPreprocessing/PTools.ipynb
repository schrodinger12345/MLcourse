{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11f56359-1aa0-4adf-ae9d-19c542ef08db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10b9d595-e520-495b-99ff-40273135d442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Spain', 'Germany'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"Data.csv\")\n",
    "df[\"Country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b32bf34c-68c6-443d-8384-c9642223599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need first three columns as independent variables , most of the times the dependent variable is situated at the end\n",
    "\n",
    "X = df.iloc[: , :-1].values # Here we selected all the rows , as for the colums we selected all columns except the last one (-1)\n",
    "\n",
    "#Purchased will the column reperesenting dependent variable \n",
    "Y = df.iloc[: , -1].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6a5b5-e878-4e5c-9055-06700b7c77d1",
   "metadata": {},
   "source": [
    "The code contains few missing data and it needs to be handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd87f163-c230-45ac-af8d-da5884d702f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "Imp = SimpleImputer(missing_values = np.nan , strategy =\"mean\")\n",
    "Imp.fit(X[: , 1:])\n",
    "X[: , 1:] = Imp.transform(X[: , 1:])\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f2fa1b-9c55-4544-a7f0-63ed1f2c404e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e6df1de-b1f8-4424-b9d5-3da76367f532",
   "metadata": {},
   "source": [
    "One-hot Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36971b9e-b8fd-495e-a987-2e32c6d22d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "#ColumnTransformer takes a tuple defining the type of tranformation , the exact transfromation and columns to be affected\n",
    "#remainder = 'passthrough' allows us to keep other unaffected columns from the dataframe in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c79d7251-b5b8-41e6-96c1-4a94a14b4422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, 44.0, 72000.0],\n",
       "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "       [0.0, 1.0, 0.0, 30.0, 54000.0],\n",
       "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "       [1.0, 0.0, 0.0, 35.0, 58000.0],\n",
       "       [0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
       "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
       "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
       "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ct.fit_transform(X) \n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2cc93f-d4b9-4600-bc61-8b8b6d4a6696",
   "metadata": {},
   "source": [
    "Encoding Dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f21e4c5-e5b4-4693-82cc-0888e87e9cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e7c4e-e037-4f39-8032-5e3de7a2a3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78273f50-325a-45ef-99e8-e555f471f08c",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "937a0ac7-0b0b-4626-a600-f3caf5698c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , Y_train , Y_test = train_test_split(X,Y, test_size = 0.2 ,random_state = 1) #random_state is just a seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d65c8c9-344e-41a5-a080-0464df18039a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
       "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "       [1.0, 0.0, 0.0, 44.0, 72000.0],\n",
       "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
       "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
       "       [1.0, 0.0, 0.0, 35.0, 58000.0]], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b3fee-8b07-4b30-8319-52eb3ec3fb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e3f09d8-2d4f-4e12-a4b2-f0c943dde601",
   "metadata": {},
   "source": [
    "Scaling data \n",
    "\n",
    "It must be done after splitting , since it can cause data leakage if done earlier \n",
    "\n",
    "For the above features we cannot apply scaling on the columns created by one hot encoding because its already between 0 and 1 , and that numerical data corresponds to a country which needs to be stay as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "102c5d93-d715-4a71-a87b-b457468312d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train[: , 3:] = scaler.fit_transform(X_train[: , 3:]) # scaler fit method returns the mean and SD of the data\n",
    "#Here we will use the same scaler instance on test data with the mean and SD of training set\n",
    "#With this technique we can tranform the test data into same format and get some relevant predictions\n",
    "X_test[:, 3:] = scaler.transform(X_test[:, 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c4b4b83-f52e-4578-bd38-4bc29e52a43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, -0.19159184384578545, -1.0781259408412425],\n",
       "       [0.0, 1.0, 0.0, -0.014117293757057777, -0.07013167641635372],\n",
       "       [1.0, 0.0, 0.0, 0.566708506533324, 0.633562432710455],\n",
       "       [0.0, 0.0, 1.0, -0.30453019390224867, -0.30786617274297867],\n",
       "       [0.0, 0.0, 1.0, -1.9018011447007988, -1.420463615551582],\n",
       "       [1.0, 0.0, 0.0, 1.1475343068237058, 1.232653363453549],\n",
       "       [0.0, 1.0, 0.0, 1.4379472069688968, 1.5749910381638885],\n",
       "       [1.0, 0.0, 0.0, -0.7401495441200351, -0.5646194287757332]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a6e5fb-07e1-4980-9d55-21c9351495b4",
   "metadata": {},
   "source": [
    "Training and predicting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b30af4b7-3a9f-4d55-8526-73f22c165eab",
   "metadata": {},
   "source": [
    "from sklearn.LinearModel import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf778f1-b077-4c41-aad5-0d9bc13300ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
